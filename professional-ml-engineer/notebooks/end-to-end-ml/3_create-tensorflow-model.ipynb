{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sealed-paris",
   "metadata": {},
   "source": [
    "# Creating Keras DNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-copyright",
   "metadata": {},
   "source": [
    "**Learning objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-bristol",
   "metadata": {},
   "source": [
    "1. Create input layers for raw features\n",
    "2. Create feature columns for inputs\n",
    "3. Create DNN dense hidden layers and output layer\n",
    "4. Build DNN model tying all of the pieces together\n",
    "5. Train and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-treat",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-stranger",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using Keras to create a DNN model to predict the weight of a baby before it is born."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-starter",
   "metadata": {},
   "source": [
    "We'll start by defining the CSV column names, label column, and column defaults for our data inputs. Then, we'll construct a `tf.data.Dataset` of features and the label from the CSV files and create input layers for the raw features. Next, we'll setup feature columns for the model inputs and build a deep neural network in Keras. We'll create a custom evaluation metric and build our DNN model. Finally, we'll train and evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-venezuela",
   "metadata": {},
   "source": [
    "## Setup environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-bigquery=1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-iceland",
   "metadata": {},
   "source": [
    "Set environment variables so that we can use them throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is: \"$PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"cloud-training-demos\" # Replace with your project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-activation",
   "metadata": {},
   "source": [
    "## Create ML datasets by sampling using BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-vitamin",
   "metadata": {},
   "source": [
    "We'll begin by sampling the BigQuery data to create smaller datasets. Let's create a BigQuery client that we'll use throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-storm",
   "metadata": {},
   "source": [
    "We need to figure out the right way to divide our hash values to get our desired splits. To do that we need to define some values to hash within the module. Feel free to play around with these values to get the perfect combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "modulo_divisor = 100\n",
    "train_percent = 80.0\n",
    "eval_percent = 10.0\n",
    "\n",
    "train_buckets = int(modulo_divisor*train_percent/100.0)\n",
    "eval_buckets = int(modulo_divisor*eval_percent/100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-things",
   "metadata": {},
   "source": [
    "We can make a series of queries to check if our bucketing values result in the correct sizes of each of our dataset splits and then adjust accordingly. Therefore, to make our code more compact and reusable, let's define a function to return the head of a dataframe produced from our queries up to a certain number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataframe_head_from_query(query, count=10):\n",
    "    \"\"\"Displays count rows from dataframe head from query.\n",
    "    \n",
    "    Args:\n",
    "        query: str, query to be run on BigQuery, results stored in dataframe.\n",
    "        count: int, number of results from head of dataframe to display.\n",
    "    Returns:\n",
    "        Dataframe head with count number of results.\n",
    "    \"\"\"\n",
    "    df = bq.query(\n",
    "        query + \" LIMIT {limit}\".format(limit=count)).to_dataframe()\n",
    "    \n",
    "    return df.head(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-apache",
   "metadata": {},
   "source": [
    "For our first query, we're going to use the original query above to get our label, features, and columns to combine into our hash which we will use to perform our repeatable splitting. There are only a limited number of years, months, days, and states in the dataset. Let's see what the hash values are. We will need to include all of these extra columns to hash on to get a fairly uniform spread of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label, features, and columns to hash and split into buckets\n",
    "hash_cols_fixed_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    year,\n",
    "    month,\n",
    "    CASE\n",
    "        WHEN day IS NULL THEN \n",
    "            CASE \n",
    "                WHEN wday IS NULL THEN 0\n",
    "                ELSE wday\n",
    "            END\n",
    "        ELSE day\n",
    "    END AS date,\n",
    "    IFNULL(state, \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state, \"Unknown\") AS mother_birth_state\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2000\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND pluarlity > 0\n",
    "    AND gestation_weeks > 0\n",
    "\"\"\"\n",
    "\n",
    "display_dataframe_head_from_query(hash_cols_fixed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-twist",
   "metadata": {},
   "source": [
    "Using `COALESCE` would provide the same result as the nested `CASE WHEN`. This is preferable when all we want is the first non-null instance. To be precise the `CASE WHEN` would become `COALESCE(wday, day, 0) AS date`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-clause",
   "metadata": {},
   "source": [
    "Next query will combine our hash columns and will leave us just with our label, features and our hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING),\n",
    "            CAST(date AS STRING),\n",
    "            CAST(state AS STRING),\n",
    "            CAST(mother_birth_state AS STRING)\n",
    "            )\n",
    "    ) AS hash_values\n",
    "FROM\n",
    "    ({CTE_hash_cols_fixed})\n",
    "\"\"\".format(CTE_hash_cols_fixed=hash_cols_fixed_query)\n",
    "\n",
    "display_dataframe_head_from_query(data_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-lover",
   "metadata": {},
   "source": [
    "The next query is going to find the counts of each of the unique 657484 `hash_values`. This will be our first step as making actual hash buckets for our split via the `GROUP BY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of the unique hash of our splitting column\n",
    "first_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    hash_values,\n",
    "    COUNT(*) AS num_records\n",
    "FROM\n",
    "    ({CTE_data})\n",
    "GROUP BY\n",
    "    hash_values\n",
    "\"\"\".format(CTE_data=data_query)\n",
    "\n",
    "display_dataframe_head_from_query(first_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-actor",
   "metadata": {},
   "source": [
    "The query below performs a second layer of bucketing where now for each of these bucket indices we count the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of records in each of the hash buckets\n",
    "second_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    ABS(MOD(hash_values, {modulo_divisor})) AS bucket_index,\n",
    "    SUM(num_records) AS num_records\n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "GROUP BY\n",
    "    ABS(MOD(hash_values, {modulo_divisor}))\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(second_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-sampling",
   "metadata": {},
   "source": [
    "The number of records is hard for us to easily understand the split, so we will normalise the count into percentage of the data in each of the hash buckets in the next query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall percentages\n",
    "percentages_query = \"\"\"\n",
    "SELECT\n",
    "    bucket_index,\n",
    "    num_records,\n",
    "    CAST(num_records AS FLOAT64) / (\n",
    "    SELECT\n",
    "        SUM(num_records)\n",
    "    FROM\n",
    "        ({CTE_second_bucketing})) AS percent_records\n",
    "FROM\n",
    "    ({CTE_second_bucketing})\n",
    "\"\"\".format(CTE_second_bucketing=second_bucketing_query)\n",
    "\n",
    "display_dataframe_head_from_query(percentages_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-fancy",
   "metadata": {},
   "source": [
    "We'll now select the range of buckets to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose hash buckets for training and pull in their statistics\n",
    "train_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"train\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= 0\n",
    "    AND bucket_index < {train_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(train_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-paraguay",
   "metadata": {},
   "source": [
    "We'll do the same by selecting the range of buckets to be used in evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose hash buckets for validation and pull in their statistics\n",
    "eval_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"eval\" AS dataset_name,\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {train_buckets}\n",
    "    AND bucket_index < {cum_eval_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets,\n",
    "    cum_eval_buckets=train_buckets+eval_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(eval_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-skating",
   "metadata": {},
   "source": [
    "Lastly, we'll select the hash buckets to be used for the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose hash buckets for testing and pull in their statistics\n",
    "test_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"test\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {cum_eval_buckets}\n",
    "    AND bucket_index < {modulo_divisor}\n",
    "\"\"\".format(\n",
    "    CTE_percentges=percentages_query,\n",
    "    cum_eval_buckets=train_buckets+eval_buckets,\n",
    "    modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-research",
   "metadata": {},
   "source": [
    "In the below query, we'll `UNION ALL` all of the datasets together so that all three sets of hash buckets will be within one table. We added `dataset_id` so that we can sort on it in the query after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union the training, validation, and test dataset statistics\n",
    "union_query = \"\"\"\n",
    "SELECT\n",
    "    0 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_train})\n",
    "UNION ALL\n",
    "SELECT\n",
    "    1 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_eval})\n",
    "UNION_ALL\n",
    "SELECT\n",
    "    2 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_test})\n",
    "\"\"\".format(CTE_train=train_query, CTE_eval=eval_query, CTE_test=test_query)\n",
    "\n",
    "display_dataframe_head_from_query(union_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-archives",
   "metadata": {},
   "source": [
    "Lastly, we'll show the final split between train, eval, and test sets. We can see both the number of records and percent of total data. It is really close to what we were hoping to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final splitting and associated statistics\n",
    "split_query = \"\"\"\n",
    "SELECT\n",
    "    dataset_id,\n",
    "    dataset_name,\n",
    "    SUM(num_records) AS num_records,\n",
    "    SUM(percent_records) AS percent_records\n",
    "FROM\n",
    "    ({CTE_union})\n",
    "GROUP BY\n",
    "    dataset_id,\n",
    "    dataset_name,\n",
    "ORDER BY\n",
    "    dataset_id\n",
    "\"\"\".format(CTE_union=union_query)\n",
    "\n",
    "display_dataframe_head_from_query(split_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-percentage",
   "metadata": {},
   "source": [
    "Now that we know that our splitting values produce a good global splitting on our data, here's a way to get a well-distributed portion of the data in such a way that the train, eval, test sets do not overlap and takes a subsample of our global splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every_n allows us to subsample from each of the hash values\n",
    "# This helps us get approximately the record counts we want\n",
    "every_n = 1000\n",
    "\n",
    "splitting_string = \"ABS(MOD(hash_values, {0} * {1}))\".format(every_n, modulo_divisor)\n",
    "\n",
    "def create_data_split_sample_df(query_string, splitting_string, lo, up):\n",
    "    \"\"\"Create a dataframe with a sample of a data split.\n",
    "    \n",
    "    Args:\n",
    "        query_string: str, query to run to generate splits.\n",
    "        splitting_string: str, modulo string to split by.\n",
    "        lo: float, lower bound for bucket filtering for split.\n",
    "        up: float, upper bound for bucket filtering for split.\n",
    "    Returns:\n",
    "        Dataframe containing data split sample.\n",
    "    \"\"\"\n",
    "    query = \"SELECT * FROM ({0}) WHERE {1} >= {2} AND {1} < {3}\".format(\n",
    "        query_string, splitting_string, int(lo), int(up))\n",
    "    \n",
    "    df = bq.query(query).to_dataframe()\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=0, up=train_percent)\n",
    "\n",
    "eval_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=train_percent, up=train_percent+eval_percent)\n",
    "\n",
    "test_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=train_percent+eval_percent, up=modulo_divisor)\n",
    "\n",
    "print(\"There are {} examples in the train dataset.\".format(len(train_df)))\n",
    "print(\"There are {} examples in the validation dataset.\".format(len(eval_df)))\n",
    "print(\"There are {} examples in the test dataset.\".format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-delicious",
   "metadata": {},
   "source": [
    "## Preprocess data using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-found",
   "metadata": {},
   "source": [
    "We'll perform a few preprocessing steps to the data in our dataset. Let's add extra rows to simulate the lack of ultrasound. That is we'll duplicate some rows and make the `is_male` field be `Unknown`. Also, if there is more than a child, we'll change the `plurality` to `Multiple(2+)`. While we're at it, we'll also change the plurality column to be a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-shelf",
   "metadata": {},
   "source": [
    "Let's start by examining the training dataset as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-amsterdam",
   "metadata": {},
   "source": [
    "Also, notice that there are some very important numeric fields that are missing in some rows (the count in Pandas doesn't count missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-option",
   "metadata": {},
   "source": [
    "It is always crucial to clean raw data before using it in ML, so we have a preprocessing step. We'll define a `preprocess` function below. Note that the mother's age is an input to our model so users will have to provide the mother's age; otherwise, our service won't work. The features we use for our model were chosen because they are such good predictors and because they are easy enough to collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \"\"\"Preprocess Pandas dataframe for augmented babyweight data.\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe containing raw babyweight data.\n",
    "    Returns:\n",
    "        Pandas dataframe containing preprocessed raw babyweight data as well\n",
    "            as simulated no ultrasound data masking some of the original data.\n",
    "    \"\"\"\n",
    "    # Clean up raw data\n",
    "    # Filter out what we don't want to use for training\n",
    "    df = df[df[\"weight_pounds\"]>0]\n",
    "    df = df[df[\"mother_age\"]>0]\n",
    "    df = df[df[\"gestation_weeks\"]>0]\n",
    "    df = df[df[\"plurality\"]>0]\n",
    "    \n",
    "    # Modify plurality field to be a string\n",
    "    twins_etc = dict(zip([1, 2, 3, 4, 5],\n",
    "                         [\"Single(1)\",\n",
    "                          \"Twins(2)\",\n",
    "                          \"Triplets(3)\",\n",
    "                          \"Quadruplets(4)\",\n",
    "                          \"Quintuplets(5)\"]))\n",
    "    df[\"plurality\"].replace(twins_etc, inplace=True)\n",
    "    \n",
    "    # Clone data and mask certain columns to simulate lack of ultrasound\n",
    "    no_ultrasound = df.copy(deep=True)\n",
    "    \n",
    "    # Modify is_male\n",
    "    no_ultrasound[\"is_male\"] = \"Unknown\"\n",
    "    \n",
    "    # Modify plurality\n",
    "    condition = no_ultrasound[\"plurality\"] != \"Single(1)\"\n",
    "    no_ultrasound.loc[condition, \"plurality\"] = \"Multiple(2+)\"\n",
    "    \n",
    "    # Concatenate both datasets together and shuffle\n",
    "    return pd.concat(\n",
    "        [df, no_ultrasound]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-hotel",
   "metadata": {},
   "source": [
    "Let's process the train, eval, test set and see a small sample of the training data after our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_df)\n",
    "eval_df = preprocess(eval_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-philadelphia",
   "metadata": {},
   "source": [
    "Let's look again at a summary of the dataset. Note that we only see numeric columns, so `plurality` does not show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-malawi",
   "metadata": {},
   "source": [
    "## Write to .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-patio",
   "metadata": {},
   "source": [
    "In the final versions, we want to read from files, not Pandas dataframes. So, we write the Pandas dataframes out as csv files. Using csv files gives us the advantage of shuffling during read. This is important for distributed training because some workers might be slower than others, and shuffling the data helps prevent the same data from being assigned to the slow workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "columns = [\"weight_pounds\",\n",
    "           \"is_male\",\n",
    "           \"mother_age\",\n",
    "           \"plurality\",\n",
    "           \"gestation_weeks\"]\n",
    "\n",
    "# Write out CSV files\n",
    "train_df.to_csv(\n",
    "    path_or_buf=\"train.csv\", columns=columns, header=False, index=False)\n",
    "eval_df.to_csv(\n",
    "    path_or_buf=\"eval.csv\", columns=columns, header=False, index=False)\n",
    "test_df.to_csv(\n",
    "    path_or_buf=\"test.csv\", columns=columns, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tail *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -5 *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-kinase",
   "metadata": {},
   "source": [
    "## Create Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-mixture",
   "metadata": {},
   "source": [
    "### Set CSV columns, label column, and column defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-solomon",
   "metadata": {},
   "source": [
    "Now that we have verified that our CSV files exist, we need to set a few things that we will be using in our input function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-filename",
   "metadata": {},
   "source": [
    "- `CSV_COLUMNS` is going to be our header name of our column. Make sure that they are in the same order as in the CSV files.\n",
    "- `LABEL_COLUMN` is the header name of the column that is our label. We will need to know this to pop it from our features dictionary.\n",
    "- `DEFAULTS` is a list with the same length as `CSV_COLUMNS`, i.e. there is a default for each column in our CSV files. Each element is a list itself with the default value for that CSV column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "# Create list of string column headers, make sure order matches\n",
    "CSV_COLUMNS = [\"weight_pounds\",\n",
    "               \"is_male\",\n",
    "               \"mother_age\",\n",
    "               \"plurality\",\n",
    "               \"gestation_weeks\"]\n",
    "\n",
    "# Add string name for label column\n",
    "LABEL_COLUMN = \"weight_pounds\"\n",
    "\n",
    "# Set default values for each CSV column as a list of lists\n",
    "# Treat is_male and plurality as strings\n",
    "DEFAULTS = [[0.0], [\"null\"], [0.0], [\"null\"], [0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-diving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-fraud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-stick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-denver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-bullet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
